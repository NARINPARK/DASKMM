{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c61820f9",
   "metadata": {},
   "source": [
    "# 0. Setting for Analaysis \n",
    "## 0.1 Load packages\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd5c8865",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T11:31:39.880982Z",
     "start_time": "2023-12-03T11:31:39.868932Z"
    }
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import math\n",
    "import random \n",
    "import time \n",
    "import math \n",
    "from scipy import stats \n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.special import gamma, factorial\n",
    "from scipy.special import psi\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn\n",
    "import sklearn.pipeline\n",
    "import sklearn.preprocessing\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler \n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.stats import t\n",
    "\n",
    "import  os\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings( 'ignore' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea3430c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ff995f7a",
   "metadata": {},
   "source": [
    "## 0.1 Load Data Set\n",
    "- credit_card data from kaggle (originally kdd-cup)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74e18d1d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-03T11:31:40.695800Z",
     "start_time": "2023-12-03T11:31:40.670518Z"
    }
   },
   "outputs": [],
   "source": [
    "# REAL DATA FITTING (credit card data) ##############################\n",
    "# 10만개로 만들어줌 #################################################\n",
    "def real_data(n):\n",
    "    import  os\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    import random\n",
    "    \n",
    "    FILE_PATH = \"C:/Users/annie/Dropbox/Research/data\"\n",
    "    csv_path = os.path.join(FILE_PATH, \"creditcard.csv\")\n",
    "    df = pd.read_csv(csv_path)\n",
    "    # number of features = 30 (features, incl. time) + 1 (label)\n",
    "    df = df.drop(['Time'], axis=1)   #drop time feature; number of input features = 29\n",
    "    df_x_values = df.drop(['Class'], axis=1)\n",
    "    \n",
    "    ###### z-normalization \n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scaler1 = StandardScaler()\n",
    "    df_x_scaled = scaler1.fit_transform(df_x_values)\n",
    "    y = df.loc[:,['Class']]\n",
    "    #y.describe()  # 0 normal, 1 anomaly \n",
    "    df_final = pd.concat([pd.DataFrame(df_x_scaled),pd.DataFrame(y)],axis=1) \n",
    "    #df_final.describe()\n",
    "    cc_data = df_final.values    #convert pandas dataframe to numpy array\n",
    "    cc_data.shape  # shape -> (284807, 30)\n",
    "    cc_data_normal1 = cc_data[cc_data[:,29]==0]    #without 'Time'\n",
    "    cc_data_normal2 = pd.DataFrame(cc_data_normal1).sample(n)\n",
    "    cc_data_normal = np.array(cc_data_normal2)\n",
    "    cc_data_fraud = cc_data[cc_data[:,29]==1]\n",
    "    # without Time feature\n",
    "    train_total_data_normal, test_total_data_normal, y_train_normal, y_test_normal = train_test_split(\n",
    "    cc_data_normal, cc_data_normal[:,29], test_size=0.1 ,random_state=1004)\n",
    "    \n",
    "    #############################################################################################\n",
    "    import sklearn\n",
    "    import sklearn.pipeline\n",
    "    import sklearn.preprocessing   \n",
    "    def process_state(state):\n",
    "        scaled = scaler.transform(state)\n",
    "        return scaled\n",
    "    #################################################################    \n",
    "    cc_data_full_final = np.concatenate((cc_data_normal[:,:29],cc_data_fraud[:,:29]), axis=0)\n",
    "    total_training_instances = len(train_total_data_normal)\n",
    "    test_total_data = np.concatenate((cc_data_fraud, test_total_data_normal), axis=0)\n",
    "\n",
    "\n",
    "\n",
    "    return train_total_data_normal, test_total_data_normal, y_train_normal, y_test_normal, test_total_data, total_training_instances, train_total_data_normal,test_total_data, cc_data_full_final \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55495b9a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-10T13:28:04.472153Z",
     "start_time": "2023-11-10T13:28:01.576874Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb56e1c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-10T13:28:07.396776Z",
     "start_time": "2023-11-10T13:28:07.379418Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7b61fe5",
   "metadata": {},
   "source": [
    "# 1. DASKNMIX model \n",
    "## 1.1 Model for no batches\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7d44d417",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-04T02:26:23.210511Z",
     "start_time": "2023-12-04T02:26:23.136136Z"
    }
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "from SKNM import *\n",
    "\n",
    "def dasknmixem(train_total_data_normal, test_total_data_normal, y_train_normal, y_test_normal, total_training_instances, \n",
    "             test_total_data, cc_data_full_final, \n",
    "            n_epochs=50, z_dim=1,k_dim=3, lr=0.001, batch_size=1024, n_hidden1=25, n_hidden2=20, n_hidden3=10, \n",
    "             n_layer1=10, lamda1=0.1, thres_point=0.99):\n",
    "    #######################################################################################\n",
    "    \n",
    "    import tensorflow as tf\n",
    "    import numpy as np\n",
    "    from scipy.optimize import minimize_scalar\n",
    "    from sklearn.mixture import GaussianMixture\n",
    "    from numpy import random\n",
    "\n",
    "    tf.reset_default_graph() \n",
    "    #그래프 초기화 bias/weight initial 돌릴때마다 새로 줄거기때문 \n",
    "    training = tf.placeholder_with_default(False, shape=())   \n",
    "    \n",
    "    \n",
    "    def encoder(x, z_dim, n_hidden1, n_hidden2, n_hidden3, dropout_prob_paper):\n",
    "\n",
    "        with tf.variable_scope(\"encoder\"):\n",
    "            init_xavier = tf.contrib.layers.xavier_initializer()\n",
    "            #he_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "            hidden1 = tf.layers.dense(x, n_hidden1, tf.nn.tanh, init_xavier)\n",
    "            hidden2 = tf.layers.dense(hidden1, n_hidden2, tf.nn.tanh, init_xavier)\n",
    "            hidden2_drop = tf.layers.dropout(hidden2, dropout_prob, training=training)\n",
    "            hidden3 = tf.layers.dense(hidden2_drop, n_hidden3, tf.nn.tanh, init_xavier)\n",
    "            hidden3_drop = tf.layers.dropout(hidden3, dropout_prob, training=training)\n",
    "            z_comp = tf.layers.dense(hidden3_drop,z_dim,None, init_xavier)\n",
    "        return z_comp\n",
    "\n",
    "    def decoder(z_comp, x_dim, n_hidden1, n_hidden2, n_hidden3,dropout_prob_paper, reuse=False):\n",
    "\n",
    "        with tf.variable_scope(\"decoder\"):\n",
    "            init_xavier = tf.contrib.layers.xavier_initializer()\n",
    "            #he_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "            hidden3 = tf.layers.dense(z_comp, n_hidden3, tf.nn.tanh, init_xavier)\n",
    "            hidden3_drop = tf.layers.dropout(hidden3, dropout_prob, training=training)\n",
    "            hidden2 = tf.layers.dense(hidden3_drop, n_hidden2, tf.nn.tanh, init_xavier)\n",
    "            hidden2_drop = tf.layers.dropout(hidden2, dropout_prob, training=training)\n",
    "            hidden1 = tf.layers.dense(hidden2_drop, n_hidden1, tf.nn.tanh, init_xavier)\n",
    "            x_hat_logits = tf.layers.dense(hidden1, x_dim, None, init_xavier)\n",
    "            #x_hat_sigmoid = tf.sigmoid(x_hat_logits)\n",
    "        return x_hat_logits\n",
    "         \n",
    "    \n",
    "    def skewem(z, k_dims):\n",
    "        max_attempts = 3  # 최대 재시도 횟수\n",
    "        best_log_lik = None\n",
    "        best_w, best_ksi, best_sigma, best_lambd = None, None, None, None\n",
    "\n",
    "        for _ in range(max_attempts):\n",
    "            try:\n",
    "                w, ksi, sigma, lambd, log_lik = sknm_em_diag(z, k_dims, tol=1e-4, max_iter=10)\n",
    "                if best_log_lik is None or log_lik > best_log_lik:\n",
    "                    best_log_lik = log_lik\n",
    "                    best_w, best_ksi, best_sigma, best_lambd = w, ksi, sigma, lambd\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred: {e}\")\n",
    "                print(\"Restarting the EM algorithm...\")\n",
    "                continue\n",
    "\n",
    "        if best_log_lik is not None:\n",
    "            return best_w, best_ksi, best_sigma, best_lambd\n",
    "        else:\n",
    "            raise RuntimeError(\"Failed to converge after multiple attempts\")\n",
    "    \n",
    "    \n",
    "    def compression_autoencoder(x, x_dim, z_dim, n_hidden1, n_hidden2, n_hidden3, dropout_prob):\n",
    "        \n",
    "        z_comp = encoder(x, z_dim, n_hidden1, n_hidden2, n_hidden3, dropout_prob)\n",
    "        x_hat = decoder(z_comp, x_dim, n_hidden1, n_hidden2, n_hidden3, dropout_prob)\n",
    "        \n",
    "    \n",
    "        #relative euclidean distance --------------------------------------------\n",
    "        ae_loss = tf.reduce_mean(tf.squared_difference(x,x_hat)) \n",
    "        recon_error = x - x_hat\n",
    "        \n",
    "        # euclidean distance \n",
    "        recon_error_magnitude = tf.cast(tf.norm(\n",
    "                recon_error, ord='euclidean', axis=1, keep_dims=True),tf.float32) #tensor of shape (batch_size, 1)\n",
    "        \n",
    "        recon_denom = tf.cast(tf.sqrt(tf.reduce_sum(tf.square(x),axis=1)),tf.float32)\n",
    "      \n",
    "        # relatvie euclidean distance로 코드 수정  -------------------------------\n",
    "        # 10000 수정해줘야함 \n",
    "        #recon_denom = tf.cast(tf.sqrt(tf.reduce_sum(tf.square(t1),axis=1)),tf.float32)\n",
    "        rel_euclidean_temp = recon_error_magnitude / recon_denom \n",
    "        relative_euclidean = tf.transpose(tf.slice(rel_euclidean_temp, [1,0],[1,batch_size]))\n",
    "        \n",
    "        # cosine similarity ----------------------------------------------------\n",
    "        x_unit = tf.nn.l2_normalize(x, dim=1)    \n",
    "        x_hat_unit = tf.nn.l2_normalize(x_hat, dim=1)\n",
    "        cos_similarity=tf.reduce_sum(\n",
    "                   tf.multiply(x_unit ,x_hat_unit),axis=1,keep_dims=True) #shape = (batch_size,1)\n",
    "\n",
    "      \n",
    "        return z_comp, x_hat, ae_loss, recon_error_magnitude, cos_similarity \n",
    "    \n",
    "    \n",
    "    \n",
    "    def energy_density(z_val, w, ksi, sigma, lambd ):\n",
    "        likelihood = np.sum(np.array(list(map(sknm_pdf, [z_val] * len(w), w, ksi, sigma, lambd))),axis=0)\n",
    "        energy_value = -np.log(likelihood)\n",
    "        energy_value_tensor = tf.convert_to_tensor(energy_value, dtype=np.float32)\n",
    "        \n",
    "        return  energy_value\n",
    "    \n",
    "  ##################################################################################\n",
    "    \n",
    "    def threshold_func(energy_input, location):\n",
    "        \n",
    "        energy_sort = np.sort(energy_input, axis=0)\n",
    "        count, bins_count = np.histogram(energy_sort, bins=100) # 0.8 부터 가파르게 오름 \n",
    "        pdf = count / sum(count)\n",
    "        cdf = np.cumsum(pdf)\n",
    "        \n",
    "        thres_loc = int(len(energy_sort)*location)\n",
    "        threshold = energy_sort[thres_loc]\n",
    "        plt.plot(bins_count[1:], cdf, label = \"CDF\") \n",
    "\n",
    "        return threshold \n",
    "    def find_optimal_threshold(test_labels, energy_value_test, energy_value_full):\n",
    "        f1_scores = []  # F1 스코어를 저장할 리스트\n",
    "        thres_points = []  # thres_point 값을 저장할 리스트\n",
    "\n",
    "        for thres_point in np.arange(0.6, 1, 0.001):  # 예시: 0부터 1까지 0.01 간격으로 시도\n",
    "            thres = threshold_func(energy_value_full, thres_point)\n",
    "            f1_result, _, _, _, _, _, _ = f1_func(test_labels, energy_value_test, thres)\n",
    "\n",
    "            f1_scores.append(f1_result)\n",
    "            thres_points.append(thres_point)\n",
    "\n",
    "        max_f1_index = np.argmax(f1_scores)  # 최대 F1 스코어의 인덱스 찾기\n",
    "        best_threshold = thres_points[max_f1_index]  # 해당 인덱스에 대응하는 thres_point 값 찾기\n",
    "        best_f1_score = f1_scores[max_f1_index]  # 최대 F1 스코어 찾기\n",
    "\n",
    "        return best_threshold\n",
    "  ##################################################################################\n",
    "\n",
    "    from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, f1_score\n",
    "\n",
    "    # threshold (energy cdf 가파르게 올라가는 지점 기준으로 임계값): 임계값 구하기 \n",
    "    # confusion matrix \n",
    "    def get_confusion_matrix_values(y_true, y_pred):\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        return(cm[0][0], cm[0][1], cm[1][0], cm[1][1])\n",
    "\n",
    "    def f1_func(labels, energy_input, thres):\n",
    "        \n",
    "        prediction = (energy_input >= thres).astype(int)\n",
    "        pred = prediction.reshape(-1)\n",
    "        real_labels = labels.astype(int)\n",
    "        \n",
    "        confusion = confusion_matrix(real_labels, pred)\n",
    "        accuracy = accuracy_score(real_labels, pred) \n",
    "        precision = precision_score(real_labels, pred)\n",
    "        recall = recall_score(real_labels, pred)\n",
    "        f1 = f1_score(real_labels, pred)\n",
    "        \n",
    "        TN, FP, FN, TP = get_confusion_matrix_values(real_labels, pred)\n",
    "    \n",
    "        \n",
    "        #print('f1:{}, 정밀도:{}, 재현율:{}'.format(f1, precision, recall))\n",
    "        #print(confusion)\n",
    "        #print(TP,FP,FN,TN)\n",
    "        return f1, precision, recall, TP, FP, FN, TN \n",
    "\n",
    "    ###############################################################################\n",
    " \n",
    "    x_dim = cc_data_full_final.shape[1]\n",
    "    d = z_dim+2  #z_dim임 \n",
    "    \n",
    "    dropout_prob = tf.placeholder(tf.float32, name='dropout_prob')\n",
    "    dropout_prob_paper = tf.placeholder(tf.float32, name='dropout_prob_paper')\n",
    "    \n",
    "    x = tf.placeholder(tf.float32, shape=[None, x_dim]) #input data 형태 만들어줌\n",
    "    energy = tf.placeholder(tf.float32, shape=[None, ])\n",
    "\n",
    "    z_comp, x_hat, ae_loss, recon_error_magnitude, cos_similarity = compression_autoencoder(x, x_dim, z_dim, n_hidden1, n_hidden2, n_hidden3, dropout_prob)\n",
    "    \n",
    "    z_concat =  tf.concat([z_comp, recon_error_magnitude , cos_similarity ], axis=1)\n",
    "    \n",
    "    energy_loss = tf.reduce_mean(energy) \n",
    "    \n",
    "    total_loss = ae_loss + lamda1*energy_loss \n",
    "    \n",
    "    #total_loss_box = []\n",
    "    #ae_loss_box = []\n",
    "    #total_loss_test_box = []\n",
    "    #ae_loss_test_box = []\n",
    "\n",
    "    \n",
    "    # training은 weight/bias update를 위함. 따라서, network 있는 곳만 optimization \n",
    "    t_vars = tf.trainable_variables()\n",
    "    all_training_vars = [var for var in t_vars if \"encoder\" or \"decoder\" in var.name]\n",
    "    training_op = tf.train.AdamOptimizer(lr).minimize(total_loss, var_list= all_training_vars)\n",
    "    number_of_batches = int(total_training_instances / batch_size)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        #np.random.shuffle(train_total_data_normal) # batch 돌릴때 \n",
    "\n",
    "        np.random.shuffle(train_total_data_normal) \n",
    "        train_data_ = train_total_data_normal[:, 0:x_dim]\n",
    "        train_label_ = train_total_data_normal[:, x_dim]\n",
    "        # test data #####################################\n",
    "        test_data = test_total_data[:,0:x_dim]\n",
    "        test_labels = test_total_data[:,x_dim]\n",
    "        ######################################          \n",
    "                \n",
    "        z_val = sess.run((z_concat),feed_dict={x: train_data_,\n",
    "                                               dropout_prob : 0.0,\n",
    "                                               dropout_prob_paper : 0.0,\n",
    "                                               training: False})\n",
    "\n",
    "        ws, ksis, sigmas, lambds = skewem(z_val, k_dim)        \n",
    "\n",
    "        energy_value = energy_density(z_val, ws, ksis, sigmas, lambds)\n",
    "\n",
    "\n",
    "        _,  total_loss_val, ae_loss_val  = sess.run((training_op, total_loss,ae_loss),\n",
    "                                                    feed_dict={x: train_data_,\n",
    "                                                               energy: energy_value,\n",
    "                                                               dropout_prob : 0.5,\n",
    "                                                               dropout_prob_paper : 0.5,\n",
    "                                                               training: True})\n",
    "\n",
    "# finish training \n",
    "# for EM algorithm -----------------------------------------------------------------------------------------------------\n",
    "# start testing \n",
    "\n",
    "        \n",
    "        z_val_new = sess.run((z_concat),feed_dict={x: train_data_ ,\n",
    "                                                   dropout_prob : 0.0,\n",
    "                                                   dropout_prob_paper : 0.0,\n",
    "                                                   training: False})\n",
    "      \n",
    "        w_new, ksi_new, sigma_new, lambd_new = skewem(z_val_new, k_dim) \n",
    "        #print(\"dof_new\", dof_new)\n",
    "\n",
    "        energy_value_new = energy_density(z_val_new, w_new, ksi_new, sigma_new, lambd_new)       \n",
    "        \n",
    "        #for comparision -------------------------------------------------------------------------------------------------------\n",
    "        \n",
    "        #total_loss \n",
    "        total_loss_val = sess.run((total_loss), \n",
    "                                  feed_dict={x: train_data_,\n",
    "                                             energy: energy_value_new,\n",
    "                                             dropout_prob : 0.0,\n",
    "                                             dropout_prob_paper : 0.0,\n",
    "                                             training: False})\n",
    "        \n",
    "        # ae_loss \n",
    "        ae_loss_value = sess.run((ae_loss),\n",
    "                                 feed_dict={x: train_data_,\n",
    "                                            energy: energy_value_new,\n",
    "                                            dropout_prob : 0.0, \n",
    "                                            dropout_prob_paper : 0.0,\n",
    "                                            training: False})\n",
    "\n",
    "    \n",
    "        # test value ----------------------------------------------------------------------------------------------------------\n",
    "        \n",
    "        z_val_test = sess.run((z_concat),feed_dict={x: test_data,\n",
    "                                                    dropout_prob : 0.0,\n",
    "                                                    dropout_prob_paper : 0.0,\n",
    "                                                    training: False})\n",
    "                \n",
    "        energy_value_test = energy_density(z_val_test, w_new, ksi_new, sigma_new, lambd_new)\n",
    "        \n",
    "        # for threshold \n",
    "        \n",
    "        z_val_full = sess.run((z_concat),feed_dict={x: cc_data_full_final,\n",
    "                                                    dropout_prob : 0.0,\n",
    "                                                    dropout_prob_paper : 0.0,\n",
    "                                                    training: False})\n",
    "                \n",
    "        energy_value_full = energy_density(z_val_full, w_new, ksi_new, sigma_new, lambd_new)\n",
    "        energy_value_full[energy_value_full == np.inf] = np.max(energy_value_full[energy_value_full != np.inf])\n",
    "        \n",
    "        best_threshold = find_optimal_threshold(test_labels, energy_value_test, energy_value_full)\n",
    "        thres = threshold_func(energy_value_full, best_threshold)\n",
    "        f1_result, precision_result, recall_result, TP_result, FP_result, FN_result, TN_result  = f1_func(test_labels, energy_value_test, thres)\n",
    "        \n",
    "    return z_val_full, f1_result, precision_result, recall_result, total_loss_val, ae_loss_value, TP_result, FP_result, FN_result, TN_result, energy_value_test, best_threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9cefc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f31c1da1",
   "metadata": {},
   "source": [
    "\n",
    "## 1.2 Model for batches\n",
    "- 배치 있는 모형\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7998f95d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-04T02:26:25.056864Z",
     "start_time": "2023-12-04T02:26:24.996027Z"
    }
   },
   "outputs": [],
   "source": [
    "from SKNM import *\n",
    "\n",
    "def dasknmixem_b(train_total_data_normal, test_total_data_normal, y_train_normal, y_test_normal, total_training_instances, test_total_data, cc_data_full_final, \n",
    "            n_epochs=50, z_dim=1, lr=0.001, batch_size=1024, n_hidden1=25, n_hidden2=20, n_hidden3=10, n_layer1=10, lamda1=0.1, thres_point=0.99):\n",
    "    #######################################################################################\n",
    "    \n",
    "    import tensorflow as tf\n",
    "    import numpy as np\n",
    "    from scipy.optimize import minimize_scalar\n",
    "    from sklearn.mixture import GaussianMixture\n",
    "    from numpy import random\n",
    "\n",
    "    tf.reset_default_graph() \n",
    "    #그래프 초기화 bias/weight initial 돌릴때마다 새로 줄거기때문 \n",
    "    training = tf.placeholder_with_default(False, shape=())   \n",
    "    \n",
    "    \n",
    "    def encoder(x, z_dim, n_hidden1, n_hidden2, n_hidden3, dropout_prob_paper):\n",
    "\n",
    "        with tf.variable_scope(\"encoder\"):\n",
    "            init_xavier = tf.contrib.layers.xavier_initializer()\n",
    "            #he_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "            hidden1 = tf.layers.dense(x, n_hidden1, tf.nn.tanh, init_xavier)\n",
    "            hidden2 = tf.layers.dense(hidden1, n_hidden2, tf.nn.tanh, init_xavier)\n",
    "            hidden2_drop = tf.layers.dropout(hidden2, dropout_prob, training=training)\n",
    "            hidden3 = tf.layers.dense(hidden2_drop, n_hidden3, tf.nn.tanh, init_xavier)\n",
    "            hidden3_drop = tf.layers.dropout(hidden3, dropout_prob, training=training)\n",
    "            z_comp = tf.layers.dense(hidden3_drop,z_dim,None, init_xavier)\n",
    "        return z_comp\n",
    "\n",
    "    def decoder(z_comp, x_dim, n_hidden1, n_hidden2, n_hidden3,dropout_prob_paper, reuse=False):\n",
    "\n",
    "        with tf.variable_scope(\"decoder\"):\n",
    "            init_xavier = tf.contrib.layers.xavier_initializer()\n",
    "            #he_init = tf.contrib.layers.variance_scaling_initializer()\n",
    "            hidden3 = tf.layers.dense(z_comp, n_hidden3, tf.nn.tanh, init_xavier)\n",
    "            hidden3_drop = tf.layers.dropout(hidden3, dropout_prob, training=training)\n",
    "            hidden2 = tf.layers.dense(hidden3_drop, n_hidden2, tf.nn.tanh, init_xavier)\n",
    "            hidden2_drop = tf.layers.dropout(hidden2, dropout_prob, training=training)\n",
    "            hidden1 = tf.layers.dense(hidden2_drop, n_hidden1, tf.nn.tanh, init_xavier)\n",
    "            x_hat_logits = tf.layers.dense(hidden1, x_dim, None, init_xavier)\n",
    "            #x_hat_sigmoid = tf.sigmoid(x_hat_logits)\n",
    "        return x_hat_logits\n",
    "         \n",
    "    \n",
    "\n",
    "    def skewem(z,k_dim): \n",
    "        w, ksi, sigma, lambd, _ =  sknm_em_diag(z, k_dim, tol=1e-4, max_iter=100)\n",
    "        return w, ksi, sigma, lambd\n",
    "    \n",
    "    \n",
    "    def compression_autoencoder(x, x_dim, z_dim, n_hidden1, n_hidden2, n_hidden3, dropout_prob):\n",
    "        \n",
    "        z_comp = encoder(x, z_dim, n_hidden1, n_hidden2, n_hidden3, dropout_prob)\n",
    "        x_hat = decoder(z_comp, x_dim, n_hidden1, n_hidden2, n_hidden3, dropout_prob)\n",
    "        \n",
    "    \n",
    "        #relative euclidean distance --------------------------------------------\n",
    "        ae_loss = tf.reduce_mean(tf.squared_difference(x,x_hat)) \n",
    "        recon_error = x - x_hat\n",
    "        \n",
    "        # euclidean distance \n",
    "        recon_error_magnitude = tf.cast(tf.norm(\n",
    "                recon_error, ord='euclidean', axis=1, keep_dims=True),tf.float32) #tensor of shape (batch_size, 1)\n",
    "        \n",
    "        recon_denom = tf.cast(tf.sqrt(tf.reduce_sum(tf.square(x),axis=1)),tf.float32)\n",
    "      \n",
    "        # relatvie euclidean distance로 코드 수정  -------------------------------\n",
    "        # 10000 수정해줘야함 \n",
    "        #recon_denom = tf.cast(tf.sqrt(tf.reduce_sum(tf.square(t1),axis=1)),tf.float32)\n",
    "        rel_euclidean_temp = recon_error_magnitude / recon_denom \n",
    "        relative_euclidean = tf.transpose(tf.slice(rel_euclidean_temp, [1,0],[1,batch_size]))\n",
    "        \n",
    "        # cosine similarity ----------------------------------------------------\n",
    "        x_unit = tf.nn.l2_normalize(x, dim=1)    \n",
    "        x_hat_unit = tf.nn.l2_normalize(x_hat, dim=1)\n",
    "        cos_similarity=tf.reduce_sum(\n",
    "                   tf.multiply(x_unit ,x_hat_unit),axis=1,keep_dims=True) #shape = (batch_size,1)\n",
    "\n",
    "      \n",
    "        return z_comp, x_hat, ae_loss, recon_error_magnitude, cos_similarity \n",
    "    \n",
    "    \n",
    "\n",
    "    def energy_density(z_val, w, ksi, sigma, lambd ):\n",
    "        likelihood = np.sum(np.array(list(map(sknm_pdf, [z_val] * len(w), w, ksi, sigma, lambd))),axis=0)\n",
    "        energy_value = -np.log(likelihood)\n",
    "        energy_value_tensor = tf.convert_to_tensor(energy_value, dtype=np.float32)\n",
    "        \n",
    "        return  energy_value\n",
    "    \n",
    "  ##################################################################################\n",
    "    \n",
    "    def threshold_func(energy_input, location):\n",
    "        energy_sort = np.sort(energy_input)\n",
    "        count, bins_count = np.histogram(energy_sort, bins=100) # 0.8 부터 가파르게 오름 \n",
    "        pdf = count / sum(count)\n",
    "        cdf = np.cumsum(pdf)\n",
    "        thres_loc = int(len(energy_sort)*location)\n",
    "        threshold = energy_sort[thres_loc]\n",
    "        plt.plot(bins_count[1:], cdf, label = \"CDF\") \n",
    "        return threshold\n",
    "\n",
    "  ##################################################################################\n",
    "\n",
    "    from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix, f1_score\n",
    "\n",
    "    # threshold (energy cdf 가파르게 올라가는 지점 기준으로 임계값): 임계값 구하기 \n",
    "    # confusion matrix \n",
    "    def get_confusion_matrix_values(y_true, y_pred):\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        return(cm[0][0], cm[0][1], cm[1][0], cm[1][1])\n",
    "\n",
    "    def f1_func(labels, energy_input, thres):\n",
    "        \n",
    "        prediction = (energy_input >= thres).astype(int)\n",
    "        pred = prediction.reshape(-1)\n",
    "        real_labels = labels.astype(int)\n",
    "        \n",
    "        confusion = confusion_matrix(real_labels, pred)\n",
    "        accuracy = accuracy_score(real_labels, pred) \n",
    "        precision = precision_score(real_labels, pred)\n",
    "        recall = recall_score(real_labels, pred)\n",
    "        f1 = f1_score(real_labels, pred)\n",
    "        \n",
    "        TN, FP, FN, TP = get_confusion_matrix_values(real_labels, pred)\n",
    "    \n",
    "        \n",
    "        #print('f1:{}, 정밀도:{}, 재현율:{}'.format(f1, precision, recall))\n",
    "        #print(confusion)\n",
    "        #print(TP,FP,FN,TN)\n",
    "        return f1, precision, recall, TP, FP, FN, TN \n",
    "\n",
    "    ###############################################################################\n",
    " \n",
    "    x_dim = cc_data_full_final.shape[1]\n",
    "    d = z_dim+2  #z_dim임 \n",
    "    dropout_prob = tf.placeholder(tf.float32, name='dropout_prob')\n",
    "    dropout_prob_paper = tf.placeholder(tf.float32, name='dropout_prob_paper') \n",
    "    x = tf.placeholder(tf.float32, shape=[None, x_dim]) #input data 형태 만들어줌\n",
    "    energy = tf.placeholder(tf.float32, shape=[None, ])\n",
    "    z_comp, x_hat, ae_loss, recon_error_magnitude, cos_similarity = compression_autoencoder(x, x_dim, z_dim, n_hidden1, n_hidden2, n_hidden3, dropout_prob)\n",
    "    z_concat =  tf.concat([z_comp, recon_error_magnitude , cos_similarity ], axis=1)\n",
    "    energy_loss = tf.reduce_mean(energy) \n",
    "    total_loss = ae_loss + lamda1*energy_loss \n",
    "    \n",
    "    # training은 weight/bias update를 위함. 따라서, network 있는 곳만 optimization \n",
    "    t_vars = tf.trainable_variables()\n",
    "    all_training_vars = [var for var in t_vars if \"encoder\" or \"decoder\" in var.name]\n",
    "    training_op = tf.train.AdamOptimizer(lr).minimize(total_loss, var_list= all_training_vars)\n",
    "    number_of_batches = int(total_training_instances / batch_size)\n",
    "    \n",
    "    with tf.Session() as sess:\n",
    "        \n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        \n",
    "        #np.random.shuffle(train_total_data_normal) # batch 돌릴때 \n",
    "        \n",
    "        for epoch in range(n_epochs):\n",
    "            \n",
    "            np.random.shuffle(train_total_data_normal) \n",
    "            train_data_ = train_total_data_normal[:, 0:x_dim]\n",
    "            train_label_ = train_total_data_normal[:, x_dim]\n",
    "            # test data #####################################\n",
    "            test_data = test_total_data[:,0:x_dim]\n",
    "            test_labels = test_total_data[:,x_dim]\n",
    "            ######################################\n",
    "            \n",
    "            for i in range(number_of_batches): \n",
    "                \n",
    "                offset = (i * batch_size) % (total_training_instances)\n",
    "                batch_x_input = train_data_[offset:(offset + batch_size), :]\n",
    "                \n",
    "                z_val = sess.run((z_concat),feed_dict={x: batch_x_input, dropout_prob : 0.0,dropout_prob_paper : 0.0,training: False})\n",
    "                \n",
    "                ws, ksis, sigmas, lambds = skewem(z_val, k_dims)        \n",
    "\n",
    "                energy_value = energy_density(z_val, ws, ksis, sigmas, lambds)\n",
    "\n",
    "        \n",
    "                _,  total_loss_val, ae_loss_val  = sess.run((training_op, total_loss,ae_loss),\n",
    "                                                            feed_dict={x: batch_x_input,\n",
    "                                                                       energy: energy_value,\n",
    "                                                                       dropout_prob : 0.5,\n",
    "                                                                       dropout_prob_paper : 0.5,\n",
    "                                                                       training: True})\n",
    "                \n",
    "\n",
    "        # finish training \n",
    "        # for EM algorithm -----------------------------------------------------------------------------------------------------\n",
    "        # start testing \n",
    "        \n",
    "        \n",
    "        z_val_new = sess.run((z_concat),feed_dict={x: train_data_ ,\n",
    "                                                   dropout_prob : 0.0,\n",
    "                                                   dropout_prob_paper : 0.0,\n",
    "                                                   training: False})\n",
    "      \n",
    "        ws, ksis, sigmas, lambds = skewem(z_val, k_dim)        \n",
    "\n",
    "        energy_value = energy_density(z_val, ws, ksis, sigmas, lambds)      \n",
    "        \n",
    "        #for comparision -------------------------------------------------------------------------------------------------------\n",
    "        \n",
    "        #total_loss \n",
    "        total_loss_val = sess.run((total_loss), \n",
    "                                  feed_dict={x: train_data_,\n",
    "                                             energy: energy_value_new,\n",
    "                                             dropout_prob : 0.0,\n",
    "                                             dropout_prob_paper : 0.0,\n",
    "                                             training: False})\n",
    "        \n",
    "        # ae_loss \n",
    "        ae_loss_value = sess.run((ae_loss),\n",
    "                                 feed_dict={x: train_data_,\n",
    "                                            energy: energy_value_new,\n",
    "                                            dropout_prob : 0.0, \n",
    "                                            dropout_prob_paper : 0.0,\n",
    "                                            training: False})\n",
    "\n",
    "    \n",
    "        # test value ----------------------------------------------------------------------------------------------------------\n",
    "        \n",
    "        z_val_test = sess.run((z_concat),feed_dict={x: test_data,\n",
    "                                                    dropout_prob : 0.0,\n",
    "                                                    dropout_prob_paper : 0.0,\n",
    "                                                    training: False})\n",
    "        \n",
    "        w_new, ksi_new, sigma_new, lambd_new = skewem(z_val_test, k_dim) \n",
    "\n",
    "        energy_value_new = energy_density(z_val_test, w_new, ksi_new, sigma_new, lambd_new)   \n",
    "        \n",
    "        # for threshold \n",
    "        \n",
    "        z_val_full = sess.run((z_concat),feed_dict={x: cc_data_full_final,\n",
    "                                                    dropout_prob : 0.0,\n",
    "                                                    dropout_prob_paper : 0.0,\n",
    "                                                    training: False})\n",
    "                \n",
    "        energy_value_full = energy_density(z_val_full, w_new, ksi_new, sigma_new, lambd_new)   \n",
    "  \n",
    "        thres = threshold_func(energy_value_full,thres_point)\n",
    "        \n",
    "        f1_result, precision_result, recall_result, TP_result, FP_result, FN_result, TN_result  = f1_func(test_labels, energy_value_test, thres)\n",
    "\n",
    "        \n",
    "    #return total_loss_val, ae_loss_value, energy_value_test, total_loss_box, ae_loss_box, total_loss_test_box, ae_loss_test_box\n",
    "    \n",
    "    return z_val_test, f1_result, precision_result, recall_result, total_loss_val, ae_loss_value, TP_result, FP_result, FN_result, TN_result, energy_value_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90f7756",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d2d3bad6",
   "metadata": {},
   "source": [
    "# 2. 데이터 적용\n",
    "## 2.1 batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fac20ed4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-04T02:26:42.714396Z",
     "start_time": "2023-12-04T02:26:26.272398Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16852\\2185919740.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m     \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[0mtrain_total_data_normal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_total_data_normal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train_normal\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test_normal\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_total_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtotal_training_instances\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_total_data_normal\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtest_total_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcc_data_full_final\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreal_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m     z_vec, f1_score, precision_val, recall_val,  loss_val, ae_loss_val, TP_val, FP_val, FN_val, TN_val, energy_value  =  dasknmixem(train_total_data_normal, test_total_data_normal, y_train_normal, y_test_normal, total_training_instances, \n\u001b[0;32m     27\u001b[0m                                                                                                                                                 test_total_data, cc_data_full_final, n_epochs=50, z_dim=1,k_dim=3, lr=0.001, batch_size=1024, n_hidden1=25, n_hidden2=20, n_hidden3=10, n_layer1=10, lamda1=0.1, thres_point=0.99)    \n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16852\\1729881916.py\u001b[0m in \u001b[0;36mreal_data\u001b[1;34m(n)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mFILE_PATH\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"C:/Users/annie/Dropbox/Research/data\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mcsv_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mFILE_PATH\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"creditcard.csv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcsv_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[1;31m# number of features = 30 (features, incl. time) + 1 (label)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Time'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;31m#drop time feature; number of input features = 29\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py37\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py37\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 586\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    587\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py37\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    486\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    487\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 488\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    489\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    490\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py37\\lib\\site-packages\\pandas\\io\\parsers\\readers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1045\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1046\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nrows\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1047\u001b[1;33m         \u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcol_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1048\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1049\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py37\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m    222\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 224\u001b[1;33m                 \u001b[0mchunks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    225\u001b[0m                 \u001b[1;31m# destructive to chunks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py37\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py37\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py37\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py37\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py37\\lib\\site-packages\\pandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\py37\\lib\\site-packages\\pandas\\core\\dtypes\\common.py\u001b[0m in \u001b[0;36mis_extension_array_dtype\u001b[1;34m(arr_or_dtype)\u001b[0m\n\u001b[0;32m   1418\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1420\u001b[1;33m \u001b[1;32mdef\u001b[0m \u001b[0mis_extension_array_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1421\u001b[0m     \"\"\"\n\u001b[0;32m   1422\u001b[0m     \u001b[0mCheck\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0man\u001b[0m \u001b[0mobject\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0mextension\u001b[0m \u001b[0marray\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#lambda = 0.013, 1 \n",
    "\n",
    "num_of_for = 20\n",
    "\n",
    "\n",
    "ae_loss = np.zeros(shape=(num_of_for,1))\n",
    "f1_value = np.zeros(shape=(num_of_for,1))\n",
    "total_loss = np.zeros(shape=(num_of_for,1))\n",
    "prec_value = np.zeros(shape=(num_of_for,1))\n",
    "recal_value = np.zeros(shape=(num_of_for,1))\n",
    "\n",
    "TP_value = np.zeros(shape=(num_of_for,1))\n",
    "FP_value = np.zeros(shape=(num_of_for,1))\n",
    "FN_value = np.zeros(shape=(num_of_for,1))\n",
    "TN_value = np.zeros(shape=(num_of_for,1))\n",
    "            \n",
    "\n",
    "math.factorial(1234567) \n",
    "start = time.time() \n",
    "\n",
    "#mu_full = pd.DataFrame()\n",
    "for i in range(0, num_of_for):\n",
    "    np.random.seed(7)\n",
    "    print(i)\n",
    "    train_total_data_normal, test_total_data_normal, y_train_normal,y_test_normal, test_total_data, total_training_instances, train_total_data_normal,test_total_data, cc_data_full_final = real_data(5000)\n",
    "    z_vec, f1_score, precision_val, recall_val,  loss_val, ae_loss_val, TP_val, FP_val, FN_val, TN_val, energy_value  =  dasknmixem(train_total_data_normal, test_total_data_normal, y_train_normal, y_test_normal, total_training_instances, \n",
    "                                                                                                                                                test_total_data, cc_data_full_final, n_epochs=50, z_dim=1,k_dim=3, lr=0.001, batch_size=1024, n_hidden1=25, n_hidden2=20, n_hidden3=10, n_layer1=10, lamda1=0.1, thres_point=0.99)    \n",
    "    print(\"f1_score\", f1_score,                                                                                                                                       \n",
    "          \"FPR_avg =\", (FP_val)/(FP_val+TN_val),\n",
    "          \"precision_avg =\", precision_val,\n",
    "          \"recall_avg =\", recall_val,\n",
    "          \"TP_avg=\", TP_val,\n",
    "          \"FP_avg=\", FP_val,\n",
    "          \"FN_avg=\", FN_val,\n",
    "          \"TN_avg=\", TN_val)\n",
    "        \n",
    "    ae_loss[i] = ae_loss_val \n",
    "    f1_value[i] = f1_score\n",
    "    \n",
    "    total_loss[i] = loss_val \n",
    "    prec_value[i] = precision_val \n",
    "    recal_value[i] = recall_val\n",
    "    \n",
    "    TP_value[i] = TP_val \n",
    "    FP_value[i] = FP_val\n",
    "    FN_value[i] = FN_val\n",
    "    TN_value[i] = TN_val\n",
    "           \n",
    "\n",
    "\n",
    "print(\"f1_score_avg =\", np.mean(f1_value),\n",
    "      \"f1_var=\", np.var(f1_value),\n",
    "      \"precision_avg =\", np.mean(prec_value),\n",
    "      \"recall_avg =\", np.mean(recal_value),\n",
    "      \"FPR_avg =\", np.mean(FP_value)/(np.mean(FP_value)+np.mean(TN_value)),\n",
    "      \"TP_avg=\", np.mean(TP_value),\n",
    "      \"FP_avg=\", np.mean(FP_value),\n",
    "      \"FN_avg=\", np.mean(FN_value),\n",
    "      \"TN_avg=\", np.mean(TN_value))\n",
    "\n",
    "end = time.time() \n",
    "print(f\"{end-start:.5f} sec\")\n",
    "\n",
    "#(pd.DataFrame(f1_value)).to_csv(\"DAGMM_credit_F1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d40cadc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-01T18:25:08.333527Z",
     "start_time": "2023-11-01T18:25:08.333527Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669f8ad6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e506665a",
   "metadata": {},
   "source": [
    "## 2.2  batches exist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fdd91086",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-04T02:26:46.269987Z",
     "start_time": "2023-12-04T02:26:46.250715Z"
    }
   },
   "outputs": [],
   "source": [
    "def real_data_sat(n):\n",
    "    import  os\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    import random\n",
    "    import sklearn\n",
    "    import sklearn.pipeline\n",
    "    import sklearn.preprocessing\n",
    "\n",
    "    FILE_PATH = \"C:/Users/annie/Dropbox/Research/data\"\n",
    "    csv_path = os.path.join(FILE_PATH, \"sat.csv\")\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df_x_values = df.drop(['label'], axis=1)\n",
    "    # z-normalization \n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scaler1 = StandardScaler()\n",
    "    df_x_scaled = scaler1.fit_transform(df_x_values)\n",
    "    y = df.loc[:,['label']]\n",
    "    df_final = pd.concat([pd.DataFrame(df_x_scaled),pd.DataFrame(y)],axis=1)\n",
    "\n",
    "    cc_data = df_final.values    #convert pandas dataframe to numpy array\n",
    "    cc_data.shape  # shape -> (284807, 30)\n",
    "    cc_data_normal1 = cc_data[cc_data[:,36]==0]    #without 'Time'\n",
    "    cc_data_normal2 = pd.DataFrame(cc_data_normal1).sample(n)\n",
    "    cc_data_normal = np.array(cc_data_normal2)    \n",
    "    cc_data_fraud = cc_data[cc_data[:,36]==1]\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    train_total_data_normal, test_total_data_normal, y_train_normal, y_test_normal = train_test_split(cc_data_normal, cc_data_normal[:,36], test_size=0.1, random_state=1004)\n",
    "\n",
    "    def process_state(state):\n",
    "        scaled = scaler.transform(state)\n",
    "        return scaled\n",
    "    cc_data_full_final = np.concatenate((cc_data_normal[:,:36],cc_data_fraud[:,:36]), axis=0)    \n",
    "    total_training_instances = len(train_total_data_normal)\n",
    "    test_total_data = np.concatenate((cc_data_fraud, test_total_data_normal), axis=0)\n",
    "    \n",
    "    return train_total_data_normal, test_total_data_normal, y_train_normal,y_test_normal, test_total_data, total_training_instances, train_total_data_normal,test_total_data, cc_data_full_final \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "13d8ff38",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-05T15:24:23.317001Z",
     "start_time": "2023-12-04T02:26:46.463176Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "f1_score 0.7031249999999999 FPR_avg = 0.305 precision_avg = 0.9055727554179567 recall_avg = 0.574656188605108 TP_avg= 1170 FP_avg= 122 FN_avg= 866 TN_avg= 278 Best_Threshold= 0.6\n",
      "1\n",
      "f1_score 0.7976523197316937 FPR_avg = 0.2875 precision_avg = 0.9254215304798963 recall_avg = 0.7008840864440079 TP_avg= 1427 FP_avg= 115 FN_avg= 609 TN_avg= 285 Best_Threshold= 0.6\n",
      "2\n",
      "f1_score 0.7684361549497848 FPR_avg = 0.275 precision_avg = 0.9240855762594893 recall_avg = 0.6576620825147348 TP_avg= 1339 FP_avg= 110 FN_avg= 697 TN_avg= 290 Best_Threshold= 0.6\n",
      "3\n",
      "f1_score 0.7448114586378252 FPR_avg = 0.2775 precision_avg = 0.91985559566787 recall_avg = 0.6257367387033399 TP_avg= 1274 FP_avg= 111 FN_avg= 762 TN_avg= 289 Best_Threshold= 0.6\n",
      "4\n",
      "f1_score 0.7799601480216339 FPR_avg = 0.2675 precision_avg = 0.9275558564658091 recall_avg = 0.6728880157170923 TP_avg= 1370 FP_avg= 107 FN_avg= 666 TN_avg= 293 Best_Threshold= 0.6\n",
      "5\n",
      "f1_score 0.7259215219976218 FPR_avg = 0.2675 precision_avg = 0.9194277108433735 recall_avg = 0.599705304518664 TP_avg= 1221 FP_avg= 107 FN_avg= 815 TN_avg= 293 Best_Threshold= 0.6\n",
      "6\n",
      "f1_score 0.8025835439483292 FPR_avg = 0.24 precision_avg = 0.9370491803278689 recall_avg = 0.7018664047151277 TP_avg= 1429 FP_avg= 96 FN_avg= 607 TN_avg= 304 Best_Threshold= 0.6\n",
      "7\n",
      "f1_score 0.7614095898324668 FPR_avg = 0.27 precision_avg = 0.9242636746143057 recall_avg = 0.6473477406679764 TP_avg= 1318 FP_avg= 108 FN_avg= 718 TN_avg= 292 Best_Threshold= 0.6\n",
      "8\n",
      "f1_score 0.7556965676377271 FPR_avg = 0.3025 precision_avg = 0.9154437456324249 recall_avg = 0.6434184675834971 TP_avg= 1310 FP_avg= 121 FN_avg= 726 TN_avg= 279 Best_Threshold= 0.6\n",
      "9\n",
      "f1_score 0.7613275613275614 FPR_avg = 0.275 precision_avg = 0.9230230930720784 recall_avg = 0.6478388998035364 TP_avg= 1319 FP_avg= 110 FN_avg= 717 TN_avg= 290 Best_Threshold= 0.6\n",
      "10\n",
      "f1_score 0.7683908045977013 FPR_avg = 0.2675 precision_avg = 0.9259002770083102 recall_avg = 0.656679764243615 TP_avg= 1337 FP_avg= 107 FN_avg= 699 TN_avg= 293 Best_Threshold= 0.6\n",
      "11\n",
      "f1_score 0.7492711370262392 FPR_avg = 0.2725 precision_avg = 0.9218077474892395 recall_avg = 0.631139489194499 TP_avg= 1285 FP_avg= 109 FN_avg= 751 TN_avg= 291 Best_Threshold= 0.6\n",
      "12\n",
      "f1_score 0.8282883874518436 FPR_avg = 0.2325 precision_avg = 0.94180225281602 recall_avg = 0.7391944990176817 TP_avg= 1505 FP_avg= 93 FN_avg= 531 TN_avg= 307 Best_Threshold= 0.6\n",
      "13\n",
      "f1_score 0.7605797101449274 FPR_avg = 0.255 precision_avg = 0.9278642149929278 recall_avg = 0.6444007858546169 TP_avg= 1312 FP_avg= 102 FN_avg= 724 TN_avg= 298 Best_Threshold= 0.6\n",
      "14\n",
      "f1_score 0.7283476204552173 FPR_avg = 0.2875 precision_avg = 0.9146250927988122 recall_avg = 0.6051080550098232 TP_avg= 1232 FP_avg= 115 FN_avg= 804 TN_avg= 285 Best_Threshold= 0.6\n",
      "15\n",
      "f1_score 0.7826829962973512 FPR_avg = 0.2525 precision_avg = 0.9315254237288135 recall_avg = 0.674852652259332 TP_avg= 1374 FP_avg= 101 FN_avg= 662 TN_avg= 299 Best_Threshold= 0.6\n",
      "16\n",
      "f1_score 0.7497820401046207 FPR_avg = 0.2875 precision_avg = 0.9181494661921709 recall_avg = 0.6335952848722987 TP_avg= 1290 FP_avg= 115 FN_avg= 746 TN_avg= 285 Best_Threshold= 0.6\n",
      "17\n",
      "f1_score 0.761520737327189 FPR_avg = 0.285 precision_avg = 0.9206128133704735 recall_avg = 0.6493123772102161 TP_avg= 1322 FP_avg= 114 FN_avg= 714 TN_avg= 286 Best_Threshold= 0.6\n",
      "18\n",
      "f1_score 0.7687016337059328 FPR_avg = 0.28 precision_avg = 0.9229181004817619 recall_avg = 0.6586444007858546 TP_avg= 1341 FP_avg= 112 FN_avg= 695 TN_avg= 288 Best_Threshold= 0.6\n",
      "19\n",
      "f1_score 0.7828067179049246 FPR_avg = 0.255 precision_avg = 0.9309410968178741 recall_avg = 0.675343811394892 TP_avg= 1375 FP_avg= 102 FN_avg= 661 TN_avg= 298 Best_Threshold= 0.6\n",
      "f1_score_avg = 0.7640647825550294 f1_var= 0.0007543690538449573 precision_avg = 0.9238922602238739 recall_avg = 0.6520137524557957 FPR_avg = 0.272125 TP_avg= 1327.5 FP_avg= 108.85 FN_avg= 708.5 TN_avg= 291.15 Thres_avg= 0.5999999999999999\n",
      "133037.22725 sec\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#lambda = 0.013, 1 \n",
    "\n",
    "num_of_for = 20\n",
    "\n",
    "\n",
    "ae_loss = np.zeros(shape=(num_of_for,1))\n",
    "f1_value = np.zeros(shape=(num_of_for,1))\n",
    "total_loss = np.zeros(shape=(num_of_for,1))\n",
    "prec_value = np.zeros(shape=(num_of_for,1))\n",
    "recal_value = np.zeros(shape=(num_of_for,1))\n",
    "\n",
    "TP_value = np.zeros(shape=(num_of_for,1))\n",
    "FP_value = np.zeros(shape=(num_of_for,1))\n",
    "FN_value = np.zeros(shape=(num_of_for,1))\n",
    "TN_value = np.zeros(shape=(num_of_for,1))\n",
    "Thres = np.zeros(shape=(num_of_for,1))                \n",
    "\n",
    "math.factorial(1234567) \n",
    "start = time.time() \n",
    "\n",
    "#mu_full = pd.DataFrame()\n",
    "for i in range(0, num_of_for):\n",
    "    np.random.seed(7)\n",
    "    print(i)\n",
    "    train_total_data_normal, test_total_data_normal, y_train_normal,y_test_normal, test_total_data, total_training_instances, train_total_data_normal,test_total_data, cc_data_full_final  = real_data_sat(4000)\n",
    "    z_vec, f1_score, precision_val, recall_val,  loss_val, ae_loss_val, TP_val, FP_val, FN_val, TN_val, energy_value, best_thres   =  dasknmixem(train_total_data_normal, test_total_data_normal, y_train_normal, y_test_normal, total_training_instances, \n",
    "                                                                                                                                                test_total_data, cc_data_full_final, n_epochs=50, z_dim=1, k_dim=3, lr=0.001, batch_size=1024,\n",
    "                                                                                                                                    n_hidden1=35, n_hidden2=20, n_hidden3=10, n_layer1=10, lamda1=0.1, thres_point=0.99)    \n",
    "    \n",
    "    print(\"f1_score\", f1_score,\n",
    "          \"FPR_avg =\", (FP_val)/(FP_val+TN_val),\n",
    "          \"precision_avg =\", precision_val,\n",
    "          \"recall_avg =\", recall_val,\n",
    "          \"TP_avg=\", TP_val,\n",
    "          \"FP_avg=\", FP_val,\n",
    "          \"FN_avg=\", FN_val,\n",
    "          \"TN_avg=\", TN_val,\n",
    "          \"Best_Threshold=\",best_thres)\n",
    "        \n",
    "    ae_loss[i] = ae_loss_val \n",
    "    f1_value[i] = f1_score\n",
    "    \n",
    "    total_loss[i] = loss_val \n",
    "    prec_value[i] = precision_val \n",
    "    recal_value[i] = recall_val\n",
    "    \n",
    "    TP_value[i] = TP_val \n",
    "    FP_value[i] = FP_val\n",
    "    FN_value[i] = FN_val\n",
    "    TN_value[i] = TN_val\n",
    "    Thres[i] = best_thres           \n",
    "\n",
    "\n",
    "print(\"f1_score_avg =\", np.mean(f1_value),\n",
    "      \"f1_var=\", np.var(f1_value),\n",
    "      \"precision_avg =\", np.mean(prec_value),\n",
    "      \"recall_avg =\", np.mean(recal_value),\n",
    "      \"FPR_avg =\", np.mean(FP_value)/(np.mean(FP_value)+np.mean(TN_value)),\n",
    "      \"TP_avg=\", np.mean(TP_value),\n",
    "      \"FP_avg=\", np.mean(FP_value),\n",
    "      \"FN_avg=\", np.mean(FN_value),\n",
    "      \"TN_avg=\", np.mean(TN_value),\n",
    "     \"Thres_avg=\",np.mean(Thres))\n",
    "\n",
    "end = time.time() \n",
    "print(f\"{end-start:.5f} sec\")\n",
    "\n",
    "(pd.DataFrame(f1_value)).to_csv(\"DASKNMIX_sat_F1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae623f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34163681",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a029a712",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a06ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def real_data_sat(n):\n",
    "    import  os\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    import random\n",
    "    import sklearn\n",
    "    import sklearn.pipeline\n",
    "    import sklearn.preprocessing\n",
    "\n",
    "    FILE_PATH = \"C:/Users/annie/Dropbox/Research/data\"\n",
    "    csv_path = os.path.join(FILE_PATH, \"satellite2.csv\")\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df.loc[df.iloc[:, 36] == 'Normal', 'Target'] = 0\n",
    "    df.loc[df.iloc[:, 36] == 'Anomaly', 'Target'] = 1\n",
    "    df_x_values = df.drop(['Target'], axis=1)\n",
    "    # z-normalization \n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    scaler1 = StandardScaler()\n",
    "    df_x_scaled = scaler1.fit_transform(df_x_values)\n",
    "    y = df.loc[:,['Target']]\n",
    "    \n",
    "    df_final = pd.concat([pd.DataFrame(df_x_scaled),pd.DataFrame(y)],axis=1)\n",
    "\n",
    "    cc_data = df_final.values    #convert pandas dataframe to numpy array\n",
    "    cc_data.shape  # shape -> (284807, 30)\n",
    "    cc_data_normal1 = cc_data[cc_data[:,36]==0]    #without 'Time'\n",
    "    cc_data_normal = np.array(cc_data_normal1)    \n",
    "    cc_data_fraud = cc_data[cc_data[:,36]==1]\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    train_total_data_normal, test_total_data_normal, y_train_normal, y_test_normal = train_test_split(cc_data_normal, cc_data_normal[:,36], test_size=0.1, random_state=1004)\n",
    "\n",
    "    def process_state(state):\n",
    "        scaled = scaler.transform(state)\n",
    "        return scaled\n",
    "    cc_data_full_final = np.concatenate((cc_data_normal[:,:36],cc_data_fraud[:,:36]), axis=0)    \n",
    "    total_training_instances = len(train_total_data_normal)\n",
    "    test_total_data = np.concatenate((cc_data_fraud, test_total_data_normal), axis=0)\n",
    "    \n",
    "    return train_total_data_normal, test_total_data_normal, y_train_normal,y_test_normal, test_total_data, total_training_instances, train_total_data_normal,test_total_data, cc_data_full_final \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38edf944",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lambda = 0.013, 1 \n",
    "\n",
    "num_of_for = 20\n",
    "\n",
    "\n",
    "ae_loss = np.zeros(shape=(num_of_for,1))\n",
    "f1_value = np.zeros(shape=(num_of_for,1))\n",
    "total_loss = np.zeros(shape=(num_of_for,1))\n",
    "prec_value = np.zeros(shape=(num_of_for,1))\n",
    "recal_value = np.zeros(shape=(num_of_for,1))\n",
    "\n",
    "TP_value = np.zeros(shape=(num_of_for,1))\n",
    "FP_value = np.zeros(shape=(num_of_for,1))\n",
    "FN_value = np.zeros(shape=(num_of_for,1))\n",
    "TN_value = np.zeros(shape=(num_of_for,1))\n",
    "Thres = np.zeros(shape=(num_of_for,1))                \n",
    "\n",
    "math.factorial(1234567) \n",
    "start = time.time() \n",
    "\n",
    "#mu_full = pd.DataFrame()\n",
    "for i in range(0, num_of_for):\n",
    "    np.random.seed(7)\n",
    "    print(i)\n",
    "    train_total_data_normal, test_total_data_normal, y_train_normal,y_test_normal, test_total_data, total_training_instances, train_total_data_normal,test_total_data, cc_data_full_final  = real_data_sat(4000)\n",
    "    z_vec, f1_score, precision_val, recall_val,  loss_val, ae_loss_val, TP_val, FP_val, FN_val, TN_val, energy_value, best_thres   =  dasknmixem(train_total_data_normal, test_total_data_normal, y_train_normal, y_test_normal, total_training_instances, \n",
    "                                                                                                                                                test_total_data, cc_data_full_final, n_epochs=50, z_dim=1, k_dim=3, lr=0.001, batch_size=1024,\n",
    "                                                                                                                                    n_hidden1=35, n_hidden2=20, n_hidden3=10, n_layer1=10, lamda1=0.1, thres_point=0.99)    \n",
    "    \n",
    "    print(\"f1_score\", f1_score,\n",
    "          \"FPR_avg =\", (FP_val)/(FP_val+TN_val),\n",
    "          \"precision_avg =\", precision_val,\n",
    "          \"recall_avg =\", recall_val,\n",
    "          \"TP_avg=\", TP_val,\n",
    "          \"FP_avg=\", FP_val,\n",
    "          \"FN_avg=\", FN_val,\n",
    "          \"TN_avg=\", TN_val,\n",
    "          \"Best_Threshold=\",best_thres)\n",
    "        \n",
    "    ae_loss[i] = ae_loss_val \n",
    "    f1_value[i] = f1_score\n",
    "    \n",
    "    total_loss[i] = loss_val \n",
    "    prec_value[i] = precision_val \n",
    "    recal_value[i] = recall_val\n",
    "    \n",
    "    TP_value[i] = TP_val \n",
    "    FP_value[i] = FP_val\n",
    "    FN_value[i] = FN_val\n",
    "    TN_value[i] = TN_val\n",
    "    Thres[i] = best_thres           \n",
    "\n",
    "\n",
    "print(\"f1_score_avg =\", np.mean(f1_value),\n",
    "      \"f1_var=\", np.var(f1_value),\n",
    "      \"precision_avg =\", np.mean(prec_value),\n",
    "      \"recall_avg =\", np.mean(recal_value),\n",
    "      \"FPR_avg =\", np.mean(FP_value)/(np.mean(FP_value)+np.mean(TN_value)),\n",
    "      \"TP_avg=\", np.mean(TP_value),\n",
    "      \"FP_avg=\", np.mean(FP_value),\n",
    "      \"FN_avg=\", np.mean(FN_value),\n",
    "      \"TN_avg=\", np.mean(TN_value),\n",
    "     \"Thres_avg=\",np.mean(Thres))\n",
    "\n",
    "end = time.time() \n",
    "print(f\"{end-start:.5f} sec\")\n",
    "\n",
    "(pd.DataFrame(f1_value)).to_csv(\"DASKNMIX_sat_new_F1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac4392f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
